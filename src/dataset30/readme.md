### dataset✔

---

우리는 Sanabria 등이 공개한 How2 데이터셋[1]을 사용합니다. 이 데이터셋은 다양한 모달리티를 이해하기 위한 대규모 데이터로, 비디오, 오디오, 비디오 자막(Transcripts) 및 요약문(Summary)으로 구성되어 있습니다.

30시간의 데이터셋은 300시간의 비디오, 오디오 및 텍스트 데이터셋에서 랜덤 샘플링하여 추출한 데이터입니다. 이 데이터셋에는 학습 데이터 1,279개, 검증 데이터 52개, 테스트 데이터 12개로 총 1,343개의 데이터가 포함되어 있습니다. 데이터 배포 관련 URL 주소는 아래와 같습니다.
(https://srvk.github.io/how2-dataset/)
<br/>
[1] Ramon Sanabria, Ozan Caglayan, Shruti Palaskar, Desmond Elliott, Loïc Barrault, Lucia Specia, and Florian Metze. 2018. "How2: a large-scale dataset for multimodal language understanding." arXiv preprint arXiv:1811.00347. ↩
