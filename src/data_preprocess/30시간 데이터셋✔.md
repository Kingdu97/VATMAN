### 30시간 데이터셋✔
> 우리는 Sanabria 등이 공개한 How2 데이터셋[1]을 사용합니다. 이 데이터셋은 다양한 모달리티를 이해하기 위한 대규모 데이터로, 비디오, 오디오, 비디오 자막(Transcripts) 및 요약문(Summary)으로 구성되어 있습니다.


- 비디오 : .npy 형태로 **개인적**으로 제공

- 오디오 : .npy 형태로 **개인적**으로 제공

- 비디오 자막(Transcripts): 화자의 음성을 텍스트로 변환한 데이터로, 비디오의 전반적인 내용을 담고 있습니다.

- 요약문(Summary): 전체 비디오에 대한 추상적인 개요를 제공합니다.

  

  

  30시간의 데이터셋은 300시간의 비디오, 오디오 및 텍스트 데이터셋에서 랜덤 샘플링하여 추출한 데이터입니다. 이 데이터셋에는 학습 데이터 1,279개, 검증 데이터 52개, 테스트 데이터 12개로 총 1,343개의 데이터가 포함되어 있습니다. 데이터 용량이 크기 때문에 데이터를 받고자 하시면 이메일 주소로 문의해 주시면 제공해 드릴 수 있습니다.

97dosan@naver.com



[1] Ramon Sanabria, Ozan Caglayan, Shruti Palaskar, Desmond Elliott, Loïc Barrault, Lucia Specia, and Florian Metze. 2018. "How2: a large-scale dataset for multimodal language understanding." arXiv preprint arXiv:1811.00347. ↩